\section{Abstract}
Multilingual Large Language Models (MLLMs) implicitly align representations across languages, creating a shared semantic space where translations map to similar vectors. However, this alignment assumes a one-to-one mapping between concepts, which is challenged by polysemy---where a single word form carries multiple distinct meanings. We investigate whether non-shared meanings in polysemous words act as a source of ``semantic interference,'' pulling embeddings away from their translations. By analyzing English-French and English-Spanish pairs using \fullmodelname, we find a statistically significant negative correlation ($ho = -0.125$, $p=0.01$) between the number of non-shared senses and cosine similarity. While monosemous translations achieve high similarity (mean $0.82$), polysemous words with non-shared meanings show measurable degradation. Crucially, however, we find that the shared semantic signal remains dominant: even with significant polysemy, translations remain far closer than random baselines ($\sim 0.37$), suggesting robust, if imperfect, concept alignment in modern MLLMs.
